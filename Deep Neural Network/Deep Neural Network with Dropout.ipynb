{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"2B Deep Neural Network with Dropout.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"1uuU60-TUVFI"},"source":["# Deep Neural Network with Dropout using Keras"]},{"cell_type":"code","metadata":{"id":"bdj61dLhUVFO","executionInfo":{"status":"ok","timestamp":1622581258817,"user_tz":-330,"elapsed":2188,"user":{"displayName":"Rishabh Kaushal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3pLHbW_Ae92_zRsqivqrvhBDsL3ioHZc-k2xF=s64","userId":"09682041678646742014"}}},"source":["import tensorflow as tf\n","\n","from tensorflow.keras import models\n","from tensorflow.keras import layers\n","\n","\n","import random\n","import numpy as np"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"B7_tBEssUVFP","executionInfo":{"status":"ok","timestamp":1622581258818,"user_tz":-330,"elapsed":9,"user":{"displayName":"Rishabh Kaushal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3pLHbW_Ae92_zRsqivqrvhBDsL3ioHZc-k2xF=s64","userId":"09682041678646742014"}}},"source":["random.seed(42)         # Initialize the random number generator.\n","np.random.seed(42)      # With the seed reset, the same set of numbers will appear every time. \n","#tf.set_random_seed(42)  # sets the graph-level random seed\n","tf.random.set_seed(42)"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4j1aBIbEUVFQ"},"source":["## Dataset"]},{"cell_type":"code","metadata":{"id":"IveJ0OGCUVFQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622581258818,"user_tz":-330,"elapsed":9,"user":{"displayName":"Rishabh Kaushal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3pLHbW_Ae92_zRsqivqrvhBDsL3ioHZc-k2xF=s64","userId":"09682041678646742014"}},"outputId":"72e779d0-8aa3-4055-a307-e045f52532b0"},"source":["# Use the MNIST dataset  of Keras.\n","\n","mnist = tf.keras.datasets.mnist\n","\n","(Xtrain, Ytrain) , (Xtest, Ytest) = mnist.load_data()"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SDSyy4NzUVFR","executionInfo":{"status":"ok","timestamp":1622581259312,"user_tz":-330,"elapsed":498,"user":{"displayName":"Rishabh Kaushal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3pLHbW_Ae92_zRsqivqrvhBDsL3ioHZc-k2xF=s64","userId":"09682041678646742014"}}},"source":["# Normalize the data\n","# 60000 input images are in the train set.\n","# 10000 input images are in the test set.\n","\n","Xtrain = Xtrain.reshape((60000, 28*28))    # reshape the input set to size 28*28. \n","Xtrain = Xtrain.astype('float32')/255      # normalize to grayscale; set datatype as float32\n","\n","Xtest = Xtest.reshape((10000, 28*28))      # reshape the input set to size 28*28. \n","Xtest = Xtest.astype('float32')/255        # normalize to grayscale; set datatype as float32\n","\n","Ytrain = tf.keras.utils.to_categorical(Ytrain)\n","Ytest = tf.keras.utils.to_categorical(Ytest)"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Fn3OKE-bUVFR"},"source":["## DNN Model"]},{"cell_type":"markdown","metadata":{"id":"bf86bSGHUVFS"},"source":["Using Keras, create the DNN or Sequential Model"]},{"cell_type":"code","metadata":{"id":"QEfNgQ2FUVFS","executionInfo":{"status":"ok","timestamp":1622581259313,"user_tz":-330,"elapsed":3,"user":{"displayName":"Rishabh Kaushal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3pLHbW_Ae92_zRsqivqrvhBDsL3ioHZc-k2xF=s64","userId":"09682041678646742014"}}},"source":["# Create a model object\n","\n","dnnModel = models.Sequential()"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"e_oFQj-aUVFS"},"source":["Add dense layers, specifying the number of units in each layer and the activation function used in the layer."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3NsFoWFaUVFT","executionInfo":{"status":"ok","timestamp":1622581259701,"user_tz":-330,"elapsed":391,"user":{"displayName":"Rishabh Kaushal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3pLHbW_Ae92_zRsqivqrvhBDsL3ioHZc-k2xF=s64","userId":"09682041678646742014"}},"outputId":"8a76a802-8b80-4b8e-88a6-7f0366529325"},"source":["# Layer 1 = input layer\n","# specify the input size for in the first layer.\n","\n","dnnModel.add(layers.Dense(50, activation='relu', input_shape= (28*28,)))\n","\n","\n","# Layer 2 = hidden layer \n","dnnModel.add(layers.Dense(60, activation='relu'))\n","\n","# Add dropout of 50% to layer 2\n","dnnModel.add(layers.Dropout(0.5))\n","\n","# Layer 3 = hidden layer \n","dnnModel.add(layers.Dense(30, activation='relu'))\n","\n","# Add dropout of 50% to layer 3\n","dnnModel.add(layers.Dropout(0.5))\n","\n","# Layer 4 = output layer\n","dnnModel.add(layers.Dense(10, activation='softmax'))\n","\n","dnnModel.summary()\n","\n"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense (Dense)                (None, 50)                39250     \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 60)                3060      \n","_________________________________________________________________\n","dropout (Dropout)            (None, 60)                0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 30)                1830      \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 30)                0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 10)                310       \n","=================================================================\n","Total params: 44,450\n","Trainable params: 44,450\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"uANFU2LLUVFU"},"source":["## Regularization and Optimizations of DNN"]},{"cell_type":"code","metadata":{"id":"79g6nVlDUVFV","executionInfo":{"status":"ok","timestamp":1622581259702,"user_tz":-330,"elapsed":5,"user":{"displayName":"Rishabh Kaushal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3pLHbW_Ae92_zRsqivqrvhBDsL3ioHZc-k2xF=s64","userId":"09682041678646742014"}}},"source":["# Configure  the model for training, by using appropriate optimizers and regularizations\n","# Available optimizer: adam, rmsprop, adagrad, sgd\n","# loss:  objective that the model will try to minimize. \n","# Available loss: categorical_crossentropy, binary_crossentropy, mean_squared_error\n","# metrics: List of metrics to be evaluated by the model during training and testing. \n","        \n","dnnModel.compile( optimizer = 'adam', loss = 'categorical_crossentropy', metrics=['accuracy'] )"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-Je411RHUVFV"},"source":["## Train the Model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SDJnzC6WUVFV","outputId":"ccb474b7-af9b-4b89-ee63-e747d1cdea77"},"source":["# train the model\n","\n","h = dnnModel.fit( Xtrain, Ytrain, validation_split=0.2, epochs=25, batch_size=64)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/25\n","750/750 [==============================] - 3s 3ms/step - loss: 0.9649 - accuracy: 0.6892 - val_loss: 0.2489 - val_accuracy: 0.9319\n","Epoch 2/25\n","750/750 [==============================] - 2s 3ms/step - loss: 0.4748 - accuracy: 0.8666 - val_loss: 0.2028 - val_accuracy: 0.9451\n","Epoch 3/25\n","750/750 [==============================] - 2s 2ms/step - loss: 0.3667 - accuracy: 0.9003 - val_loss: 0.1717 - val_accuracy: 0.9526\n","Epoch 4/25\n","750/750 [==============================] - 2s 3ms/step - loss: 0.3110 - accuracy: 0.9160 - val_loss: 0.1592 - val_accuracy: 0.9571\n","Epoch 5/25\n","750/750 [==============================] - 2s 3ms/step - loss: 0.2769 - accuracy: 0.9260 - val_loss: 0.1470 - val_accuracy: 0.9628\n","Epoch 6/25\n","750/750 [==============================] - 2s 3ms/step - loss: 0.2457 - accuracy: 0.9329 - val_loss: 0.1437 - val_accuracy: 0.9650\n","Epoch 7/25\n","750/750 [==============================] - 2s 3ms/step - loss: 0.2338 - accuracy: 0.9348 - val_loss: 0.1448 - val_accuracy: 0.9643\n","Epoch 8/25\n","750/750 [==============================] - 2s 3ms/step - loss: 0.2100 - accuracy: 0.9402 - val_loss: 0.1484 - val_accuracy: 0.9652\n","Epoch 9/25\n","750/750 [==============================] - 2s 2ms/step - loss: 0.2021 - accuracy: 0.9436 - val_loss: 0.1534 - val_accuracy: 0.9643\n","Epoch 10/25\n","750/750 [==============================] - 2s 3ms/step - loss: 0.1896 - accuracy: 0.9461 - val_loss: 0.1504 - val_accuracy: 0.9656\n","Epoch 11/25\n","750/750 [==============================] - 2s 3ms/step - loss: 0.1874 - accuracy: 0.9474 - val_loss: 0.1529 - val_accuracy: 0.9665\n","Epoch 12/25\n","750/750 [==============================] - 2s 2ms/step - loss: 0.1780 - accuracy: 0.9501 - val_loss: 0.1450 - val_accuracy: 0.9681\n","Epoch 13/25\n","750/750 [==============================] - 2s 2ms/step - loss: 0.1680 - accuracy: 0.9508 - val_loss: 0.1578 - val_accuracy: 0.9681\n","Epoch 14/25\n","750/750 [==============================] - 2s 3ms/step - loss: 0.1635 - accuracy: 0.9524 - val_loss: 0.1647 - val_accuracy: 0.9680\n","Epoch 15/25\n","750/750 [==============================] - 2s 3ms/step - loss: 0.1596 - accuracy: 0.9526 - val_loss: 0.1584 - val_accuracy: 0.9684\n","Epoch 16/25\n","750/750 [==============================] - 2s 3ms/step - loss: 0.1509 - accuracy: 0.9557 - val_loss: 0.1532 - val_accuracy: 0.9687\n","Epoch 17/25\n","750/750 [==============================] - 2s 3ms/step - loss: 0.1528 - accuracy: 0.9544 - val_loss: 0.1579 - val_accuracy: 0.9697\n","Epoch 18/25\n","750/750 [==============================] - 2s 3ms/step - loss: 0.1425 - accuracy: 0.9564 - val_loss: 0.1728 - val_accuracy: 0.9669\n","Epoch 19/25\n","750/750 [==============================] - 2s 3ms/step - loss: 0.1387 - accuracy: 0.9586 - val_loss: 0.1769 - val_accuracy: 0.9689\n","Epoch 20/25\n","750/750 [==============================] - 2s 3ms/step - loss: 0.1358 - accuracy: 0.9595 - val_loss: 0.1796 - val_accuracy: 0.9675\n","Epoch 21/25\n","750/750 [==============================] - 2s 3ms/step - loss: 0.1356 - accuracy: 0.9599 - val_loss: 0.1814 - val_accuracy: 0.9691\n","Epoch 22/25\n","750/750 [==============================] - 2s 3ms/step - loss: 0.1326 - accuracy: 0.9602 - val_loss: 0.1819 - val_accuracy: 0.9696\n","Epoch 23/25\n","750/750 [==============================] - 2s 3ms/step - loss: 0.1299 - accuracy: 0.9597 - val_loss: 0.1761 - val_accuracy: 0.9696\n","Epoch 24/25\n","454/750 [=================>............] - ETA: 0s - loss: 0.1218 - accuracy: 0.9625"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aDOtOX0AUVFW"},"source":["print('Final training loss \\t', h.history['loss'][-1])\n","print('Final training accuracy ', h.history['accuracy'][-1])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GUZ48ISvUVFW"},"source":["# plot the training  accuracy  \n","import matplotlib.pyplot as plt\n","\n","plt.plot(h.history['accuracy'], label='train')\n","plt.plot(h.history['val_accuracy'], label='validation')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.title('Plot of Accuracy')\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FhYlSeLLUVFX"},"source":["# plot the traininig loss \n","\n","\n","plt.plot(h.history['loss'], label='train')\n","plt.plot(h.history['val_loss'], label='validation')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.title('Plot of Loss')\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fpeXP784UVFX"},"source":["## Testing the Model"]},{"cell_type":"code","metadata":{"id":"2rcagsw7UVFX"},"source":["# testing the model\n","\n","testLoss, testAccuracy = dnnModel.evaluate( Xtest, Ytest)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ftrbMQxZUVFY"},"source":["print('Testing loss \\t', testLoss)\n","print('Testing accuracy ', testAccuracy)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QOlhQBlHUVFY"},"source":["Modify the code to get a better testing accuracy.\n","- Change the number of hidden units\n","- Increase the number of hidden layers\n","- Use a different optimizer"]}]}